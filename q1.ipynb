{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tk in /home/areddy27/.local/lib/python3.11/site-packages (0.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmeans8 as kmeans\n",
    "\n",
    "data = kmeans.loadCSV(\n",
    "    \"/scratch/areddy27/dm-hw3-24/kmeans_data/data.csv\"\n",
    ")\n",
    "label = kmeans.loadCSV(\n",
    "    \"/scratch/areddy27/dm-hw3-24/kmeans_data/label.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "k = len(set(label))\n",
    "print(k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE for jaccard-K-means: 9999.0\n",
      "SSE for euclidean-K-means: 25400856764.478363\n",
      "SSE for cosine-K-means: 2456.424805130752\n"
     ]
    }
   ],
   "source": [
    "k = len(set(label))  \n",
    "metrics = [ \"jaccard\", \"euclidean\",\"cosine\"]\n",
    "results = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    clustering_result = kmeans.kmeans(data, k, metric)\n",
    "    results[metric] = clustering_result\n",
    "    print(f\"SSE for {metric}-K-means: {results[metric]['withinss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running K-means with euclidean metric...\n",
      "Accuracy for euclidean-K-means: 61.17%\n",
      "\n",
      "Running K-means with cosine metric...\n",
      "Accuracy for cosine-K-means: 61.24%\n",
      "\n",
      "Running K-means with jaccard metric...\n",
      "Accuracy for jaccard-K-means: 11.35%\n",
      "\n",
      "The best metric is cosine with an accuracy of 61.24%\n"
     ]
    }
   ],
   "source": [
    "def label_clusters(clusters, labels, df):\n",
    "    instance_to_label = {tuple(instance): labels[idx] for idx, instance in enumerate(df)}\n",
    "    cluster_labels = []\n",
    "    for cluster in clusters:\n",
    "        if not cluster:\n",
    "            cluster_labels.append(None)\n",
    "            continue\n",
    "        label_counts = {}\n",
    "        for instance in cluster:\n",
    "            instance_label = instance_to_label[tuple(instance)]\n",
    "            label_counts[instance_label] = label_counts.get(instance_label, 0) + 1\n",
    "        most_frequent_label = max(label_counts, key=label_counts.get)\n",
    "        cluster_labels.append(most_frequent_label)\n",
    "    return cluster_labels\n",
    "\n",
    "def calculate_accuracy(clusters, cluster_labels, actual_labels, df):\n",
    "    instance_to_actual_label = {tuple(instance): actual_labels[idx] for idx, instance in enumerate(df)}\n",
    "    correct_assignments = 0\n",
    "    total_assignments = 0\n",
    "    for cluster_index, cluster in enumerate(clusters):\n",
    "        cluster_label = cluster_labels[cluster_index]\n",
    "        if cluster_label is None:\n",
    "            continue\n",
    "        for instance in cluster:\n",
    "            actual_label = instance_to_actual_label[tuple(instance)]\n",
    "            if actual_label == cluster_label:\n",
    "                correct_assignments += 1\n",
    "            total_assignments += 1\n",
    "    accuracy = correct_assignments / total_assignments if total_assignments > 0 else 0\n",
    "    return accuracy * 100\n",
    "\n",
    "def compare_kmeans_accuracies(data, true_labels, k, metrics=[\"euclidean\", \"cosine\", \"jaccard\"]):\n",
    "    accuracies = {}\n",
    "    for metric in metrics:\n",
    "        print(f\"\\nRunning K-means with {metric} metric...\")\n",
    "        # clustering_result = kmeans.kmeans(data, k, metric=metric)\n",
    "        clusters = results[metric][\"clusters\"]\n",
    "        # Assign labels to clusters\n",
    "        cluster_labels = label_clusters(clusters, true_labels, data)\n",
    "        # Calculate accuracy\n",
    "        accuracy = calculate_accuracy(clusters, cluster_labels, true_labels, data)\n",
    "        accuracies[metric] = accuracy\n",
    "        print(f\"Accuracy for {metric}-K-means: {accuracy:.2f}%\")\n",
    "    # Determine the best metric\n",
    "    best_metric = max(accuracies, key=accuracies.get)\n",
    "    print(f\"\\nThe best metric is {best_metric} with an accuracy of {accuracies[best_metric]:.2f}%\")\n",
    "    return accuracies\n",
    "\n",
    "metrics = [\"euclidean\", \"cosine\", \"jaccard\"]\n",
    "accuracies = compare_kmeans_accuracies(data, label, k, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION\n",
      "SSE for euclidean-K-means\n",
      "iterations: 100\n",
      "time_taken: 663.5364742279053\n",
      "SSE for cosine-K-means\n",
      "iterations: 100\n",
      "time_taken: 551.1184651851654\n",
      "SSE for jaccard-K-means\n",
      "iterations: 100\n",
      "time_taken: 172.26075553894043\n"
     ]
    }
   ],
   "source": [
    "k = len(set(label))  # Number of clusters based on unique labels\n",
    "metrics = [\"euclidean\", \"cosine\", \"jaccard\"]  # Metrics to compare\n",
    "\n",
    "clustering_result_itr = {}\n",
    "print(\"ITERATION\")\n",
    "for metric in metrics:\n",
    "    res = kmeans.kmeans(data, k, metric=metric, stop_type=\"iteration\")\n",
    "    print(f\"SSE for {metric}-K-means\")\n",
    "    \n",
    "    clustering_result_itr[metric] = res\n",
    "    print(f\"iterations: {clustering_result_itr[metric]['iterations']}\")\n",
    "    print(f\"time_taken: {clustering_result_itr[metric]['time_taken']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENTROID\n",
      "SSE for euclidean-K-means\n",
      "iterations: 81\n",
      "time_taken: 534.8787603378296\n",
      "SSE for cosine-K-means\n",
      "iterations: 70\n",
      "time_taken: 383.4009907245636\n",
      "SSE for jaccard-K-means\n",
      "iterations: 33\n",
      "time_taken: 93.82068181037903\n"
     ]
    }
   ],
   "source": [
    "k = len(set(label))  # Number of clusters based on unique labels\n",
    "metrics = [\"euclidean\", \"cosine\", \"jaccard\"]  # Metrics to compare\n",
    "clustering_result_centroid = {}\n",
    "print(\"CENTROID\")\n",
    "for metric in metrics:\n",
    "    res = kmeans.kmeans(data, k, metric=metric, stop_type=\"centroid\")\n",
    "    print(f\"SSE for {metric}-K-means\")\n",
    "    \n",
    "    clustering_result_centroid[metric] = res\n",
    "    print(f\"iterations: {clustering_result_centroid[metric]['iterations']}\")\n",
    "    print(f\"time_taken: {clustering_result_centroid[metric]['time_taken']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE\n",
      "SSE for euclidean-K-means\n",
      "iterations: 121\n",
      "time_taken: 813.3401138782501\n",
      "SSE for cosine-K-means\n",
      "iterations: 18\n",
      "time_taken: 100.37496900558472\n",
      "SSE for jaccard-K-means\n",
      "iterations: 3\n",
      "time_taken: 15.547428846359253\n"
     ]
    }
   ],
   "source": [
    "k = len(set(label))  # Number of clusters based on unique labels\n",
    "metrics = [ \"euclidean\", \"cosine\", \"jaccard\" ]  # Metrics to compare\n",
    "clustering_result_sse = {}\n",
    "print(\"SSE\")\n",
    "for metric in metrics:\n",
    "    res = kmeans.kmeans(data, k, metric=metric, stop_type=\"sse\")\n",
    "    print(f\"SSE for {metric}-K-means\")\n",
    "    clustering_result_sse[metric] = res\n",
    "    print(f\"iterations: {clustering_result_sse[metric]['iterations']}\")\n",
    "    print(f\"time_taken: {clustering_result_sse[metric]['time_taken']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE Values for different Stopping Conditions\n",
      "---------------------------------------------\n",
      "Centroid\n",
      "Euclidean : 25533557387.060757\n",
      "Cosine : 2462.5295006930282\n",
      "Jaccard : 9999.0\n",
      "---------------------------------------------\n",
      "Iterations (100)\n",
      "Euclidean : 25578081537.80641\n",
      "Cosine : 2473.0464869584493\n",
      "Jaccard : 9999.0\n",
      "---------------------------------------------\n",
      "SSE Increase\n",
      "Euclidean : 25318302482.14896\n",
      "Cosine : 2472.954883111413\n",
      "Jaccard : 9998.998091603053\n"
     ]
    }
   ],
   "source": [
    "print(\"SSE Values for different Stopping Conditions\")\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Centroid\")\n",
    "for metric in metrics:\n",
    "    \n",
    "    print(metric.capitalize(), \":\", clustering_result_centroid[metric]['withinss'])\n",
    "\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Iterations (100)\")\n",
    "for metric in metrics:\n",
    "    print(metric.capitalize(), \":\",clustering_result_itr[metric]['withinss'])\n",
    "\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"SSE Increase\")\n",
    "for metric in metrics:\n",
    "    print(metric.capitalize(), \":\",clustering_result_sse[metric]['withinss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
